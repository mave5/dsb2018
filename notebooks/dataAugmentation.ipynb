{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=gpu0,floatX=float32\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import random\n",
    "import warnings\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import cv2\n",
    "from scipy import ndimage\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# get package versions\n",
    "def get_version(*vars):\n",
    "    for var in vars:\n",
    "        module = __import__(var)    \n",
    "        print ('%s: %s' %(var,module.__version__))\n",
    "    \n",
    "# package version    \n",
    "get_version('keras','numpy','matplotlib','cv2','theano')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set some parameters\n",
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "TRAIN_PATH = '../data/stage1_train/'\n",
    "TEST_PATH = '../data/stage1_test/'\n",
    "\n",
    "# normalization type\n",
    "norm_type='zeroMeanUnitStd'\n",
    "\n",
    "netinfo='trainTest2'\n",
    "initialLearningRate=3e-4\n",
    "\n",
    "\n",
    "# Get train and test IDs\n",
    "train_ids = next(os.walk(TRAIN_PATH))[1]\n",
    "test_ids = next(os.walk(TEST_PATH))[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calcualte dice\n",
    "def calc_dice(X,Y,d=0):\n",
    "    N=X.shape[d]    \n",
    "    # intialize dice vector\n",
    "    dice=np.zeros([N,1])\n",
    "\n",
    "    for k in range(N):\n",
    "        x=X[k,0] >.5 # convert to logical\n",
    "        y =Y[k,0]>.5 # convert to logical\n",
    "\n",
    "        # number of ones for intersection and union\n",
    "        intersectXY=np.sum((x&y==1))\n",
    "        unionXY=np.sum(x)+np.sum(y)\n",
    "\n",
    "        if unionXY!=0:\n",
    "            dice[k]=2* intersectXY/(unionXY*1.0)\n",
    "            #print 'dice is: %0.2f' %dice[k]\n",
    "        else:\n",
    "            dice[k]=1\n",
    "            #print 'dice is: %0.2f' % dice[k]\n",
    "        #print 'processing %d, dice= %0.2f' %(k,dice[k])\n",
    "    return np.mean(dice),dice\n",
    "\n",
    "def preprocess(X,xnormType=None):\n",
    "    if xnormType=='minus1plus1':\n",
    "        X=X.astype('float32')\n",
    "        X/=np.max(X)\n",
    "        X-=0.5\n",
    "        X=X*2\n",
    "    elif xnormType=='zeroMeanUnitStd':\n",
    "        X=X.astype('float32')\n",
    "        # we do this per channel\n",
    "        for c in range(X.shape[1]):\n",
    "            X[:,c]-=np.mean(X[:,c])\n",
    "            stdXc=np.std(X[:,c])\n",
    "            if stdXc>0.0:\n",
    "                X[:,c]/=stdXc\n",
    "    else:\n",
    "        print('no normalization!')\n",
    "    return X\n",
    "\n",
    "def array_stats(X):\n",
    "    X=np.asarray(X)\n",
    "    print ('array shape: ',X.shape, X.dtype)\n",
    "    #print 'min: %.3f, max:%.3f, avg: %.3f, std:%.3f' %(np.min(X),np.max(X),np.mean(X),np.std(X))\n",
    "    print ('min: {}, max: {}, avg: {:.3}, std:{:.3}'.format( np.min(X),np.max(X),np.mean(X),np.std(X)))\n",
    "\n",
    "def resizeY(Y,origHW):\n",
    "    # Y shape is N*1*H*W\n",
    "    N=Y.shape[0] \n",
    "    Yr=[]\n",
    "    for k in range(N):\n",
    "        temp=resize(Y[k,0], (origHW[k,0], origHW[k,1]), mode='constant', preserve_range=True)\n",
    "        Yr.append(temp)\n",
    "    return Yr\n",
    "    \n",
    "def loadData0(ids,path2data):\n",
    "    print('loading '+path2data)\n",
    "    # Get and resize train images and masks\n",
    "    X = np.zeros((len(ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "    Y = np.zeros((len(ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "    origHW=np.zeros((len(ids),3),dtype='uint16') # store original dimension for later use\n",
    "    \n",
    "    print('Getting and resizing images and masks ... ')\n",
    "    #sys.stdout.flush()\n",
    "    for n, id_ in enumerate(ids):\n",
    "        path = path2data + id_   \n",
    "        #print(path)\n",
    "        img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
    "        h,w,c=img.shape\n",
    "        origHW[n]=img.shape\n",
    "        img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "        X[n] = img\n",
    "        mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "        try:\n",
    "            for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "                mask_ = imread(path + '/masks/' + mask_file)\n",
    "                mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n",
    "                                              preserve_range=True), axis=-1)\n",
    "                mask = np.maximum(mask, mask_)\n",
    "            Y[n] = mask\n",
    "        except:\n",
    "            Y=[]\n",
    "    if len(Y):\n",
    "        Y=np.transpose(Y,(0,3,1,2))\n",
    "    return np.transpose(X,(0,3,1,2)),Y,origHW\n",
    "\n",
    "def loadData(path2h5,data_type='train'):\n",
    "    if not os.path.exists(path2h5):\n",
    "        X_train,Y_train,HW_train=loadData0(train_ids,TRAIN_PATH)\n",
    "        h5file=h5py.File(path2h5,'w-')\n",
    "        h5file['X_train']=X_train\n",
    "        h5file['Y_train']=Y_train\n",
    "        h5file['HW_train']=HW_train\n",
    "            \n",
    "        X_test,Y_test,HW_test=loadData0(test_ids,TEST_PATH)\n",
    "        h5file['X_test']=X_test\n",
    "        h5file['Y_test']=Y_test\n",
    "        h5file['HW_test']=HW_test\n",
    "    else:\n",
    "        print('loading '+ path2h5)\n",
    "        h5file=h5py.File(path2h5,'r')\n",
    "        X_train=h5file['X_train']\n",
    "        Y_train=h5file['Y_train']\n",
    "        HW_train=h5file['HW_train']\n",
    "        X_test=h5file['X_test']\n",
    "        Y_test=h5file['Y_test']\n",
    "        HW_test=h5file['HW_test']\n",
    "    if data_type==\"train\":\n",
    "        return X_train,Y_train,np.array(HW_train,'uint16')\n",
    "    elif data_type==\"leader\":\n",
    "        return X_test,Y_test,np.array(HW_train,'uint16')\n",
    "\n",
    "    \n",
    "    \n",
    "# train test model\n",
    "def train_test_model(X_train,y_train,X_test,y_test,params_train):\n",
    "    foldnm=params_train['foldnm']  \n",
    "    pre_train=params_train['pre_train'] \n",
    "    batch_size=params_train['batch_size'] \n",
    "    augmentation=params_train['augmentation'] \n",
    "    path2weights=params_train['path2weights'] \n",
    "    path2model=params_train['path2model'] \n",
    "    norm_type=params_train['norm_type'] \n",
    "    \n",
    "    print('batch_size: %s, Augmentation: %s' %(batch_size,augmentation))\n",
    "    \n",
    "    print 'fold %s training in progress ...' %foldnm\n",
    "    # load last weights\n",
    "    if pre_train== True:\n",
    "        if  os.path.exists(path2weights):\n",
    "            model.load_weights(path2weights)\n",
    "            print 'previous weights loaded!'\n",
    "        else:\n",
    "            raise IOError('weights does not exist!!!')\n",
    "    else:\n",
    "        if  os.path.exists(path2weights):\n",
    "            model.load_weights(path2weights)\n",
    "            print (path2weights)\n",
    "            print ('previous weights loaded!')\n",
    "            train_status='previous weights'\n",
    "            return train_status\n",
    "    \n",
    "    # path to csv file to save scores\n",
    "    path2scorescsv = weightfolder+'/scores.csv'\n",
    "    first_row = 'train,test'\n",
    "    with open(path2scorescsv, 'w+') as f:\n",
    "        f.write(first_row + '\\n')\n",
    "           \n",
    "    # Fit the model\n",
    "    start_time=time.time()\n",
    "    scores_test=[]\n",
    "    scores_train=[]\n",
    "    if params_train['loss']=='dice': \n",
    "        best_score = 0\n",
    "        previous_score = 0\n",
    "    else:\n",
    "        best_score = 1e6\n",
    "        previous_score = 1e6\n",
    "    patience = 0\n",
    "    \n",
    "    # convert class vectors to binary class matrices\n",
    "    train_generator = generator(X_train,y_train,batch_size)\n",
    "    \n",
    "    for epoch in range(params_train['nbepoch']):\n",
    "    \n",
    "        print ('epoch: %s,  Current Learning Rate: %.1e' %(epoch,model.optimizer.lr.get_value()))\n",
    "        #seed = np.random.randint(0, 999999)\n",
    "    \n",
    "        if augmentation:\n",
    "            model.fit_generator(train_generator, steps_per_epoch=len(xtr)/batch_size, epochs=1,verbose=0)            \n",
    "        else:\n",
    "            hist=model.fit(preprocess(X_train,norm_type), y_train, batch_size=batch_size,epochs=1, verbose=0)\n",
    "            \n",
    "        # evaluate on test and train data\n",
    "        score_test=model.evaluate(preprocess(X_test,norm_type),y_test,verbose=0)\n",
    "        score_train=np.mean(hist.history['loss'])\n",
    "       \n",
    "        print ('score_train: %s, score_test: %s' %(score_train,score_test))\n",
    "        scores_test=np.append(scores_test,score_test)\n",
    "        scores_train=np.append(scores_train,score_train)    \n",
    "\n",
    "        # check for improvement    \n",
    "        if (score_test<=best_score):\n",
    "            print (\"!!!!!!!!!!!!!!!!!!!!!!!!!!! viva, improvement!!!!!!!!!!!!!!!!!!!!!!!!!!!\") \n",
    "            best_score = score_test\n",
    "            patience = 0\n",
    "            model.save_weights(path2weights)  \n",
    "            model.save(path2model)\n",
    "            \n",
    "        # learning rate schedule\n",
    "        if score_test>previous_score:\n",
    "            #print \"Incrementing Patience.\"\n",
    "            patience += 1\n",
    "\n",
    "        # learning rate schedule                \n",
    "        if patience == params_train['max_patience']:\n",
    "            params_train['learning_rate'] = params_train['learning_rate']/2\n",
    "            print (\"Upating Current Learning Rate to: \", params_train['learning_rate'])\n",
    "            model.optimizer.lr.set_value(params_train['learning_rate'])\n",
    "            print (\"Loading the best weights again. best_score: \",best_score)\n",
    "            model.load_weights(path2weights)\n",
    "            patience = 0\n",
    "        \n",
    "        # save current test score\n",
    "        previous_score = score_test    \n",
    "        \n",
    "        # store scores into csv file\n",
    "        with open(path2scorescsv, 'a') as f:\n",
    "            string = str([score_train,score_test])\n",
    "            f.write(string + '\\n')\n",
    "           \n",
    "    \n",
    "    print ('model was trained!')\n",
    "    elapsed_time=(time.time()-start_time)/60\n",
    "    print ('elapsed time: %d  mins' %elapsed_time)      \n",
    "\n",
    "    # train test progress plots\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.plot(scores_test)\n",
    "    plt.plot(scores_train)\n",
    "    plt.title('train-validation progress',fontsize=20)\n",
    "    plt.legend(('test','train'),fontsize=20)\n",
    "    plt.xlabel('epochs',fontsize=20)\n",
    "    plt.ylabel('loss',fontsize=20)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(weightfolder+'/train_val_progress.png')\n",
    "    plt.show()\n",
    "    \n",
    "    print 'training completed!'\n",
    "    train_status='completed!'\n",
    "    return train_status    \n",
    "\n",
    "def grays_to_RGB(img):\n",
    "    # turn 2D grayscale image into grayscale RGB\n",
    "    return np.dstack((img, img, img))\n",
    "\n",
    "\n",
    "def image_with_mask(img, mask,color=(0,255,0)):\n",
    "    mask=np.asarray(mask,dtype='uint8') \n",
    "    \n",
    "    if len(img.shape)==2:\n",
    "        img_color = grays_to_RGB(img)\n",
    "    else:\n",
    "        img_color =img\n",
    "\n",
    "    mask2=mask[:,:,0]\n",
    "    for c1 in range(mask.shape[2]):\n",
    "        mask2=np.logical_or(mask2,mask[:,:,c1])\n",
    "    mask2=np.array(255*mask2,'uint8')\n",
    "        \n",
    "    mask_edges = cv2.Canny(mask2, 100, 200) > 0\n",
    "    #plt.imshow(mask_edges)\n",
    "    maximg=np.max(img)\n",
    "    img_color[mask_edges, 0] = maximg*color[0]  # set channel 0 to bright red, green & blue channels to 0\n",
    "    img_color[mask_edges, 1] = maximg*color[1]\n",
    "    img_color[mask_edges, 2] = maximg*color[2]\n",
    "    return img_color\n",
    "\n",
    "def disp_img_2masks(img,mask1=None,mask2=None,r=1,c=1,d=0,indices=None):\n",
    "    if mask1 is None:\n",
    "        mask1=np.zeros(img.shape,dtype='uint8')\n",
    "    else:\n",
    "        mask1=np.array(mask1,dtype='uint8')\n",
    "    if mask2 is None:\n",
    "        mask2=np.zeros(img.shape,dtype='uint8')\n",
    "    else:        \n",
    "        mask2=np.array(mask2,dtype='uint8')    \n",
    "        \n",
    "    N=r*c    \n",
    "    if d==2:\n",
    "        # convert to N*C*H*W\n",
    "        img=np.transpose(img,(2,0,1))\n",
    "        img=np.expand_dims(img,axis=1)\n",
    "        \n",
    "        mask1=np.transpose(mask1,(2,0,1))\n",
    "        mask1=np.expand_dims(mask1,axis=1)\n",
    "\n",
    "        mask2=np.transpose(mask2,(2,0,1))\n",
    "        mask2=np.expand_dims(mask2,axis=1)\n",
    "        \n",
    "    if indices is None:    \n",
    "        indices=np.random.randint(img.shape[0],size=N)\n",
    "    \n",
    "    # collect images and masks\n",
    "    I1=[np.transpose(img[i],(1,2,0)) for i in indices]\n",
    "    M1=[np.transpose(mask1[i],(1,2,0)) for i in indices]\n",
    "    M2=[np.transpose(mask2[i],(1,2,0)) for i in indices]\n",
    "    \n",
    "    C1=(0,255,0)\n",
    "    C2=(255,0,0)\n",
    "    for k in range(N):    \n",
    "        imgmask=image_with_mask(I1[k],M1[k],C1)\n",
    "        imgmask=image_with_mask(imgmask,M2[k],C2)\n",
    "        plt.subplot(r,c,k+1)\n",
    "        plt.imshow(imgmask)\n",
    "        plt.title(indices[k])\n",
    "    plt.show()            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2h5='../data/trainTestH'+str(IMG_HEIGHT)+'W'+str(IMG_WIDTH)+'.hdf5'\n",
    "X,Y,HW_train=loadData(path2h5,'train')\n",
    "array_stats(X)\n",
    "array_stats(Y)\n",
    "array_stats(HW_train)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(HW_train[:,0],100)\n",
    "plt.xlim([0,400])\n",
    "plt.xticks(range(0,400,32))\n",
    "plt.title('H')\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(HW_train[:,1],100)\n",
    "plt.xlim([0,400])\n",
    "plt.xticks(range(0,400,32))\n",
    "plt.title('W')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "disp_img_2masks(img=X,mask1=Y,r=2,c=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from image import ImageDataGenerator\n",
    "\n",
    "# random data generator\n",
    "datagen = ImageDataGenerator(featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False,\n",
    "        rotation_range=5,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.01,\n",
    "        zoom_range=0.01,\n",
    "        channel_shift_range=0.0,\n",
    "        fill_mode='constant',\n",
    "        cval=0.0,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,)\n",
    "        #data_format=\"channels_first\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs1 , targets,  batchsize, shuffle=True, augment=True):\n",
    "    assert len(inputs1) == len(targets)\n",
    "    if augment==True:\n",
    "        if shuffle:\n",
    "            indices = np.arange(len(inputs1))\n",
    "            np.random.shuffle(indices)\n",
    "        for start_idx in range(0, len(inputs1) - batchsize + 1, batchsize):\n",
    "            if shuffle:\n",
    "                excerpt = indices[start_idx:start_idx + batchsize]\n",
    "            else:\n",
    "                excerpt = slice(start_idx, start_idx + batchsize)\n",
    "            x = inputs1[excerpt]\n",
    "            y = targets[excerpt] \n",
    "            for  xxt,yyt in datagen.flow(x, y , batch_size=x.shape[0]):\n",
    "                x = xxt.astype(np.float32) \n",
    "                y = yyt \n",
    "                break\n",
    "    else:\n",
    "        x=inputs1\n",
    "        y=targets\n",
    "\n",
    "    #yield np.array(x,np.uint8), np.array(y, dtype=np.uint8)         \n",
    "    return np.array(x,np.uint8), np.array(y, dtype=np.uint8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=X.shape[0]\n",
    "i=0\n",
    "array_stats(X)\n",
    "array_stats(Y)\n",
    "X_batch,Y_batch=iterate_minibatches(X,Y,N,shuffle=False,augment=True)  \n",
    "Y_batch=Y_batch[:,0][:,np.newaxis]\n",
    "array_stats(X_batch)\n",
    "array_stats(Y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "disp_img_2masks(img=X_batch,mask1=Y_batch[:,0][:,np.newaxis],r=2,c=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gammaAug(images,gamma):\n",
    "    # images shape: N*C*H*W\n",
    "    #print ('before gamma:', np.mean(image))\n",
    "    n1,c1,_,_=images.shape\n",
    "    for k1 in range(n1):\n",
    "        #for k2 in range(c1):\n",
    "        g = (2 * np.random.rand() - 1) * gamma + 1.\n",
    "        images[k1]=(images[k1]) ** g\n",
    "    #print ('after gamma:', np.mean(image))\n",
    "    return images\n",
    "\n",
    "array_stats(X)\n",
    "Xgamma=gammaAug(X.value,0.3)\n",
    "array_stats(Xgamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "disp_img_2masks(img=Xgamma,mask1=Y,r=2,c=3);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
